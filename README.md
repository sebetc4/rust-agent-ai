# ğŸ¤– agents-rs

> Un environnement local et interopÃ©rable pour exÃ©cuter des **agents LLM** entiÃ¨rement **offline**

[![Rust](https://img.shields.io/badge/Rust-2021-orange.svg)](https://www.rust-lang.org/)
[![Tauri](https://img.shields.io/badge/Tauri-2.0-blue.svg)](https://tauri.app/)
[![React](https://img.shields.io/badge/React-18-61DAFB.svg)](https://reactjs.org/)
[![MCP](https://img.shields.io/badge/MCP-2024--11--05-green.svg)](https://modelcontextprotocol.io)

## ğŸ¯ Objectif

CrÃ©er une plateforme d'agents LLM locale permettant :
- ğŸ”’ **ConfidentialitÃ© totale** : Tout s'exÃ©cute localement
- ğŸ”Œ **InteropÃ©rabilitÃ©** : Compatible avec le protocole MCP (Claude, LM Studio)
- ğŸš€ **Performance** : Backend Rust natif
- ğŸ§° **Extensible** : SystÃ¨me de plugins pour ajouter des outils

## âœ¨ FonctionnalitÃ©s actuelles

### âœ… Backend Rust complet
- Moteur LLM modulaire (prÃªt pour llama.cpp)
- Gestionnaire de contexte conversationnel
- Serveur MCP JSON-RPC sur HTTP
- SystÃ¨me de plugins/outils dynamique
- 9 commandes Tauri exposÃ©es au frontend

### ğŸ”§ Outils intÃ©grÃ©s
- `echo` : Test de communication
- `file_reader` : Lecture de fichiers locaux
- `file_writer` : Ã‰criture de fichiers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tauri Frontend (React)  â”‚
â”‚   Interface utilisateur   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ IPC Commands
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Backend Rust (Core)    â”‚
â”‚ â”œâ”€ Moteur LLM             â”‚
â”‚ â”œâ”€ Serveur MCP (port 3000)â”‚
â”‚ â”œâ”€ Gestionnaire contexte  â”‚
â”‚ â””â”€ Registre d'outils      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Plugins MCP externes    â”‚
â”‚  (fichiers, API, scripts) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Voir [BACKEND_ARCHITECTURE.md](./BACKEND_ARCHITECTURE.md) pour plus de dÃ©tails.

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis
- **Rust** 1.70+ ([installer](https://rustup.rs/))
- **Node.js** 18+ et **pnpm** ([installer pnpm](https://pnpm.io/installation))
- **Tauri dependencies** ([voir la doc](https://tauri.app/start/prerequisites/))
- **CMake** et **Clang** (pour llama.cpp):
  ```bash
  # Fedora/RHEL
  sudo dnf install cmake clang
  
  # Ubuntu/Debian
  sudo apt install cmake libclang-dev
  
  # Arch
  sudo pacman -S cmake clang
  ```

### Installation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/votre-repo/agents-rs.git
cd agents-rs

# Installer les dÃ©pendances frontend
pnpm install

# Compiler le backend Rust
cargo build --manifest-path src-tauri/Cargo.toml

# TÃ©lÃ©charger un modÃ¨le (exemple: Qwen3-1.7B)
mkdir -p models
# Placer votre fichier .gguf dans models/

# Tester le modÃ¨le
./test-quick.sh
```

## ğŸ§ª Tests Rapides

```bash
# Test simple (1 prompt)
cargo run --manifest-path src-tauri/Cargo.toml --example simple

# Test complet (3 prompts + stats)
./test-quick.sh

# Mode interactif
./test-interactive.sh

# Tests unitaires
cargo test --manifest-path src-tauri/Cargo.toml --lib llm::tests
```

Voir [TEST-GUIDE.md](./TEST-GUIDE.md) pour plus de dÃ©tails.

## ğŸ“¦ Structure du projet

```
agents-rs/
â”œâ”€â”€ src/                      # Frontend React
â”œâ”€â”€ src-tauri/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ backend/          # â­ Architecture backend
â”‚       â”‚   â”œâ”€â”€ llm_engine.rs
â”‚       â”‚   â”œâ”€â”€ context.rs
â”‚       â”‚   â”œâ”€â”€ mcp_server.rs
â”‚       â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ lib.rs            # Commandes Tauri
â”‚       â””â”€â”€ main.rs
â”œâ”€â”€ models/                   # ModÃ¨les GGUF Ã  placer ici
â”œâ”€â”€ tools/                    # Plugins MCP personnalisÃ©s
â””â”€â”€ config.yaml               # Configuration
```

## ğŸ§  Utilisation

### Via le frontend (TypeScript)

```typescript
import { invoke } from '@tauri-apps/api/core';

// CrÃ©er une session
const sessionId = await invoke('create_session', { 
  title: 'Ma conversation' 
});

// Ajouter un message utilisateur
await invoke('add_message', { 
  sessionId, 
  role: 'user', 
  content: 'Bonjour !' 
});

// GÃ©nÃ©rer une rÃ©ponse (quand LLM sera intÃ©grÃ©)
const response = await invoke('generate_response', { 
  prompt: 'Bonjour !' 
});

// ExÃ©cuter un outil
const result = await invoke('execute_tool', {
  toolName: 'file_reader',
  arguments: { path: './README.md' }
});
```

### Via HTTP (MCP)

```bash
# Health check
curl http://localhost:3000/

# Lister les outils
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "method": "tools/list",
    "id": 1
  }'

# Appeler un outil
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "method": "tools/call",
    "params": {
      "name": "echo",
      "arguments": {"text": "Hello!"}
    },
    "id": 2
  }'
```

## ğŸ”® Roadmap

| Ã‰tape | Description | Ã‰tat |
|-------|-------------|------|
| ğŸ§© 1 | Architecture backend Rust | âœ… **TerminÃ©** |
| ğŸ§  2 | Serveur MCP minimal | âœ… **TerminÃ©** |
| ğŸ§° 3 | SystÃ¨me d'outils/plugins | âœ… **TerminÃ©** |
| ğŸ¦™ 4 | IntÃ©gration llama.cpp | ğŸš§ En cours |
| ğŸ’¬ 5 | Interface chat React | â³ Ã€ faire |
| ğŸ”— 6 | CompatibilitÃ© Claude/LM Studio | ğŸ”œ Futur |
| ğŸ“¦ 7 | Release bÃªta | ğŸ”œ Futur |

## ğŸ› ï¸ DÃ©veloppement

### Tests
```bash
cargo test --manifest-path src-tauri/Cargo.toml
```

### Build de production
```bash
pnpm tauri build
```

### Ajouter un outil MCP

Voir [tools/README.md](./tools/README.md) pour crÃ©er vos propres outils.

## ğŸ“– Documentation

- [Architecture Backend](./BACKEND_ARCHITECTURE.md)
- [Instructions Copilot](./.github/copilot-instructions.md)
- [Model Context Protocol](https://modelcontextprotocol.io)

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Voir [CONTRIBUTING.md](./CONTRIBUTING.md) (Ã  crÃ©er).
